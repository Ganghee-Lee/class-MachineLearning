{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MachineLearning_assignment05.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"mount_file_id":"1L1Nv0OQnPPubBMgPE7MEFfGkZbCT2BR3","authorship_tag":"ABX9TyODF9h8dGk/YkTIvfnxbrIU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"p8YYY4xSdjgX","colab_type":"text"},"source":["# 1. Load data\n","\n","---\n","\\\n","     \n","* data.txt 파일을 동일 디렉터리에 위치시키고 데이터를 읽었습니다.     \n"," \n","* 읽은 데이터들을 visualize할때 label이 0인 data는 blue, 1인 data는 red로 시각화했습니다. "]},{"cell_type":"code","metadata":{"id":"rQztJWwbX1aP","colab_type":"code","colab":{}},"source":["import csv\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","'''\n","1. Data\n"," - Config\n"," - Load Data\n","'''\n","\n","# Config\n","learning_rate=0.0002014\n","opt_threshold=0.00000002748\n","t0, t1, t2=-10., -5., 10\n","theta=np.array([[t0, t1, t2]])\n","\n","# Load data\n","path = \"drive/My Drive/Classroom/Machine Learning (2) 2020-1\\\n","/class-MachineLearning/assignment05/\"\n","train=[]\n","test=[]\n","\n","data = np.genfromtxt(path+\"data.txt\", delimiter=',')\n","\n","x = data[:, 0]\n","y = data[:, 1]\n","m = len(x)\n","\n","label = data[:, 2]\n","\n","x_label0 = x[label == 0]\n","x_label1 = x[label == 1]\n","\n","y_label0 = y[label == 0]\n","y_label1 = y[label == 1]\n","temp=np.ones(m)\n","\n","input_data=np.hstack((temp.reshape(-1, 1), x.reshape(-1, 1), y.reshape(-1, 1)))\n","\n","plt.figure(figsize=(8, 8))\n","plt.scatter(x_label0, y_label0, alpha=1, c='b')\n","plt.scatter(x_label1, y_label1, alpha=1, c='r')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Swp6Grj_h-Wj","colab_type":"text"},"source":["# 2. Optimize Logistic regression\n","\n","---\n","\\\n","     \n","* train data에 대한 hypothesis, objective function, gradient descent를 정의했습니다.     \n"," \n","* 연산과정들을 matrix로 빠르게 계산하기 위해 np.dot함수를 사용했습니다.     \n","\n","* 각 theta(feature)들에 맞는 update함수를 정의함으로써 학습동안 각각의 theta들이 모두 update되도록 했습니다.    \n","\n","* 수렴하는 기준을 0.00000002748로 설정하고 iteration에 대한 loss변화량이 이 기준값보다    \n","  작으면 수렴했다 판단했습니다.    \n","\n","* Objective function에서 log0으로 인한 -inf값 방지를 위해 동일한 notation이지만 inf를    \n","생성하지 않도록 식을 수정했습니다.\n"]},{"cell_type":"code","metadata":{"id":"8ma_LieeX3v_","colab_type":"code","colab":{}},"source":["'''\n","2. Hypothesis\n"," - Define hypothesis and sigmoid hypothesis.\n","\n","3. Objective function\n"," - Define objective function, modify notation for J.\n","\n","4. Gradient Descent\n"," - Define derivations.\n"," - Update theta0, theta1, theta2.\n","'''\n","\n","# Define hypothesis\n","def sigmoid_h() :\n","    return 1/(1+np.exp(-z))\n","    \n","def hypothesis() :\n","    return input_data.dot(theta.T).flatten()\n","\n","z=hypothesis()\n","h=sigmoid_h()\n","\n","# Define objective function\n","def objective_function() :\n","    positive_z=np.array(list(map(lambda x : max(x, 0), z)))\n","    J = np.sum(positive_z - z*label + np.log(1+np.exp(-np.abs(z)))) / m\n","    return J\n","\n","# Define derivations\n","def dev() :    \n","    dev0=np.sum(h-label) / m\n","    dev1=np.sum((h-label)*x) / m\n","    dev2=np.sum((h-label)*y) / m\n","    dev=[dev0, dev1, dev2]\n","    return dev\n","\n","# Update theta0, theta1, theta2, theta3\n","def gradient_descent() :\n","    return (theta[0][0]-(learning_rate*dev0), theta[0][1]-(learning_rate*dev1),\\\n","            theta[0][2]-(learning_rate*dev2))\n","    \n","J_list=[]\n","theta0_list=[]\n","theta1_list=[]\n","theta2_list=[]\n","h_list=[]\n","# Train\n","count=0\n","for i in range(20000) :\n","    h_list.append(h)\n","    count+=1\n","    J=objective_function()\n","\n","    J_list.append(J)\n","    \n","    theta0_list.append(theta[0][0])\n","    theta1_list.append(theta[0][1])\n","    theta2_list.append(theta[0][2])\n","    \n","\n","    dev0, dev1, dev2 = dev()\n","    temp0, temp1, temp2 = theta[0]\n","    theta[0][0], theta[0][1], theta[0][2] = gradient_descent()\n","    z=hypothesis()\n","    h=sigmoid_h()\n","\n","    if len(J_list)>=2 and \\\n","    abs(J_list[-2] - J_list[-1]) <opt_threshold :\n","        break\n","print(\"theta0 : \", theta[0][0])\n","print(\"theta1 : \", theta[0][1])\n","print(\"theta2 : \", theta[0][2])\n","print(\"loss : \", J)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRqoJhefm7me","colab_type":"text"},"source":["# 3. Model parameters\n","\n","---\n","\\\n"," - update를 할때마다 변하는 theta0, theta1, theta2, theta3의 값들을 따로 리스트에 저장해뒀었습니다.\n"," \n","*   각 iteration마다 위 theta들이 각각 어떻게 변하는지 시각화했습니다.\n"]},{"cell_type":"code","metadata":{"id":"ZPlNUcny-cy4","colab_type":"code","colab":{}},"source":["'''\n","Visualize theta\n","'''\n","plt.figure(figsize=(10, 7))\n","plt.plot(theta0_list, color='red', label='theta0')\n","plt.plot(theta1_list, color='green', label='theta1')\n","plt.plot(theta2_list, color='blue', label='theta2')\n","plt.legend(loc='upper right')\n","plt.xlabel(\"iteration\")\n","#plt.xlim(left=-1000)\n","plt.ylabel(\"value\")\n","plt.title(\"Parameter (theta0 & theta1\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1vyu_7sxnDLy","colab_type":"text"},"source":["# 4. Training error\n","\n","---\n","\\\n"," - training data에 대해서 update를 할때마다 train_J_list에 그동안의 loss 값들을 넣었습니다.  \n"," \n","*   각 iteration마다 loss값이 어떻게 변하는지 시각화했습니다.\n"]},{"cell_type":"code","metadata":{"id":"MiqY96zeiheI","colab_type":"code","colab":{}},"source":["'''\n","Visualize Loss\n","'''\n","plt.figure(figsize=(10, 7))\n","plt.plot(J_list, color='blue', label='train')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"cost\")\n","plt.legend(loc='upper right')\n","plt.title(\"Energy values (train)\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RkAm-OT5nLbg","colab_type":"text"},"source":["# 5. Visualize classifier\n","\n","---\n","\\\n","*   그래프에서 x와 y에 대한 범위는 30~100으로 설정하고    \n","해당 범위 내에서 0.5씩 증가하면서 각각 141개의 값을 갖게됩니다.    \n","\n","*   meshgrid를 통해서 x와 y값들을 좌표평면에 대응시킬 수 있는 grid matrix로 만듭니다.     \n","\n","*   각 x, y 좌표에 따른 hypothesis값을 구하는 함수를 정의하고     \n","0에 가까울수록 blue, 1에 가까울수록 red로 plot했습니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"ZbB360tKH3yY","colab_type":"code","colab":{}},"source":["'''\n","Visualize classifier\n","'''\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","def H(x, y) :\n","    H=theta[0][0] + theta[0][1] * x + theta[0][2] * y\n","    return 1/(1+np.exp(-H))\n","\n","grid_x=np.linspace(start=30, stop=100, num=141)\n","grid_y=np.linspace(start=30, stop=100, num=141)\n","# Construct meshgrid between x and y\n","grid_x, grid_y=np.meshgrid(grid_x, grid_y)      \n","\n","\n","fig = plt.figure(figsize=(12, 8))\n","\n","grid_H=np.array([H(x, y) for (x, y) in \\\n","                 zip(np.ravel(grid_x), np.ravel(grid_y))])\n","grid_H = grid_H.reshape(grid_x.shape)\n","\n","plt.scatter(grid_x, grid_y, c=grid_H, cmap='jet', s=3)\n","plt.scatter(x_label0, y_label0, alpha=1, c='b')\n","plt.scatter(x_label1, y_label1, alpha=1, c='r')\n","plt.show()"],"execution_count":0,"outputs":[]}]}