{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MachineLearning_assignment03.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"mount_file_id":"1YRxlZ4H_ZvZAt6PBdthv4D9RgKP3YdqQ","authorship_tag":"ABX9TyOhfsqXXSiW9DUMqifHNV9i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KhjYfSMp41ci","colab_type":"text"},"source":["# 1. Load data\n","\n","---\n","\\\n","     \n","* data.csv 파일을 동일 디렉터리에 위치시키고 데이터를 읽었습니다.    \n"," \n","*   data.csv에서 읽은 data를 점의 형태로 시각화했습니다."]},{"cell_type":"code","metadata":{"id":"1YdpWFzMT7Ud","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","'''\n","After read the data from data.csv file, visualize data\n","'''\n","\n","path = \"drive/My Drive/Classroom/Machine Learning (2) 2020-1\\\n","/class-MachineLearning/assignment03/data.csv\"\n","data = np.genfromtxt(path, delimiter=',')\n","\n","x_data = data[:, 0]\n","y_data = data[:, 1]\n","\n","plt.figure(figsize=(8, 8))\n","plt.scatter(x_data, y_data, color='black')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"esonagCF5hX2","colab_type":"text"},"source":["# 2. Optimize linear function    \n","\n","---\n","\\\n"," - 주어진 x data와 y data를 표현할 수 있는 linear function을 regression 시킵니다.     \n","     \n","learning rate와 data size를 포함한 configuration들을 정의하고    \n","objective function, gradient descent 등.. 의 함수를 train을 위해 정의했습니다.    \n","optimize를 통해 얻어진 theta0와 theta1은 25와 10에 근사합니다.     \n","즉, 찾고자했던 linear function은 $f(x)=10x+25$ 입니다.\n","\n","\\\n","*   Optimize된 linear function과 input data를 시각화했습니다.\n"]},{"cell_type":"code","metadata":{"id":"MpCqKEPtcXhi","colab_type":"code","colab":{}},"source":["'''\n","Define\n"," - Config\n"," - objective function\n"," - derivation of objective function for each theta0 and theta1\n"," - gradient descent\n","\n","Get Optimized theta0 and theta1 using gradient descent.\n","Visualize optimized linear function.\n","'''\n","\n","#Config\n","learning_rate=0.001\n","m=len(x_data)\n","theta0, theta1=-30, -30\n","\n","# Initialize linear model\n","h=theta1*x_data+theta0\n","\n","# Define objective function\n","def objective_function() :\n","    J = np.sum((h-y_data)**2) / (2*m)\n","    return J\n","\n","# Define derivations\n","def dev() :    \n","    dev0=np.sum(h-y_data) / m\n","    dev1=np.sum((h-y_data)*x_data) / m\n","    return dev0, dev1\n","\n","# Update theta0 and theta1\n","def gradient_descent() :\n","    return theta0-(learning_rate*dev0), theta1-(learning_rate*dev1)\n","\n","J_list=[]\n","theta0_list=[]\n","theta1_list=[]\n","# Train\n","count=0\n","while(1) :\n","    count+=1\n","    J=objective_function()\n","    J_list.append(J)\n","    theta0_list.append(theta0)\n","    theta1_list.append(theta1)\n","    dev0, dev1 = dev()\n","    temp0, temp1 = theta0, theta1\n","    theta0, theta1 = gradient_descent()\n","    h=theta0+theta1*x_data\n","    if(temp0==theta0) and (temp1==theta1) :\n","        break\n","print(\"theta0 : \", theta0)\n","print(\"theta1 : \", theta1)\n","print(\"loss : \", J)\n","# Visualize data and linear model\n","plt.figure(figsize=(8, 8))\n","plt.scatter(x_data, y_data, color='black')\n","plt.plot(x_data, h, color='red')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.title('Linear regression results')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZaL1vAkH7HUQ","colab_type":"text"},"source":["# 3. Visualize energy surface    \n","\n","---\n","\\\n"," - 각각의 theta0, theta1에 대한 J(loss)를 시각화했습니다.     \n"," \n","\\\n","그래프에서 theta0와 theta1에 대한 범위는 -30~30으로 설정하고    \n","해당 범위 내에서 0.1씩 증가하면서 각각 601개의 값을 갖게됩니다.    \n","meshgrid를 통해서 theta0와 theta1값들을 좌표평면에 대응시킬 수 있는 grid matrix로 만듭니다.     \n","각 theta0, theta1 좌표에 따른 J(loss)값을 구하는 함수를 정의하고     \n","matplotlib에서 제공하는 contourf3D함수를 통해서 energy surface를 시각화했습니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"AiWlQhiZe5I_","colab_type":"code","colab":{}},"source":["'''\n","Construct meshgrid field\n","Visualize loss at each theta0 and theta1 in 3-dimension\n","'''\n","\n","import mpl_toolkits.mplot3d.axes3d as p3\n","\n","def J(t0, t1) :\n","    h=x_data*t1 + t0\n","    J = np.sum((h-y_data)**2) / (2*m)\n","    return J\n","grid_theta0=np.linspace(start=-30, stop=30, num=601)\n","grid_theta1=np.linspace(start=-30, stop=30, num=601)\n","# Construct meshgrid between x and y\n","grid_theta0, grid_theta1=np.meshgrid(grid_theta0, grid_theta1)      \n","\n","\n","fig = plt.figure(figsize=(13, 8))\n","ax = plt.axes(projection='3d')\n","\n","ax.set_xlabel(\"theta1\")\n","ax.set_ylabel(\"theta0\")\n","ax.set_zlabel(\"J(theta0, theta1)\")\n","\n","grid_J=np.array([J(t1, t0) for (t1, t0) in \\\n","                 zip(np.ravel(grid_theta1), np.ravel(grid_theta0))])\n","grid_J = grid_J.reshape(grid_theta0.shape)\n","\n","#ax.plot_surface(grid_theta0, grid_theta1, grid_J, cmap=plt.cm.hot, alpha=0.6)\n","ax.contourf3D(grid_theta0, grid_theta1, grid_J, 200, cmap=plt.cm.rainbow, alpha=0.3)\n","#ax.plot(theta1_list,theta0_list, J_list,color = 'r', marker = '>', markerfacecolor='r', markeredgecolor='black', markersize=5, alpha = .9)\n","\n","#ax.plot([t for t in theta0_list], [t2 for t2 in theta1_list], cost , markerfacecolor='r', markeredgecolor='r', marker='.', markersize=2)\n","ax.view_init(20, 45)\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtbocOol8fS7","colab_type":"text"},"source":["# 4. Visualize gradient descent path    \n","\n","---\n","\\\n"," - 위에서 그린 energy surface위에 gradient descent path를 함께 시각화했습니다.     \n"," \n","\\\n","theta0와 theta1을 -30, -30으로 초기화하고 train과정에서 update되는 과정을 눈으로 확인하기 위해     \n","update될때마다 각각 list안에 값을 저장하였습니다.     \n","초기화한 값부터 최종 수렴한 값까지 각각의 (theta0, theta1, J) 좌표를 energy surface위에 plot하고     \n","이를 화살표로 나타냄으로써 gradient descent되는 path를 확인할 수 있습니다.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ndVuw8tQ3m9x","colab_type":"code","colab":{}},"source":["'''\n","Visualize gradient descent path on energy surface\n","'''\n","\n","fig = plt.figure(figsize=(13, 8))\n","ax = plt.axes(projection='3d')\n","\n","ax.set_xlabel(\"theta1\")\n","ax.set_ylabel(\"theta0\")\n","ax.set_zlabel(\"J(theta0, theta1)\")\n","\n","grid_J=np.array([J(t1, t0) for (t1, t0) in \\\n","                 zip(np.ravel(grid_theta1), np.ravel(grid_theta0))])\n","grid_J = grid_J.reshape(grid_theta0.shape)\n","\n","#ax.plot_surface(grid_theta0, grid_theta1, grid_J, cmap=plt.cm.hot, alpha=0.6)\n","ax.contourf3D(grid_theta0, grid_theta1, grid_J, 200, cmap=plt.cm.rainbow, alpha=0.3)\n","ax.plot(theta1_list,theta0_list, J_list,color = 'black', marker = '>', \\\n","        markerfacecolor='r', markeredgecolor='r', markersize=5, alpha = .9)\n","\n","#ax.plot([t for t in theta0_list], [t2 for t2 in theta1_list], cost , markerfacecolor='r', markeredgecolor='r', marker='.', markersize=2)\n","ax.view_init(20, 45)\n","plt.show()"],"execution_count":0,"outputs":[]}]}