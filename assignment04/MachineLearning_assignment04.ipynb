{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MachineLearning_assignment04.ipynb","provenance":[],"private_outputs":true,"mount_file_id":"1X6tzH4YXgffuBGTfk7dvpk8vq-R01CfE","authorship_tag":"ABX9TyMCL+5N67IUX6GmYbb6d7tg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0YRpin2haXWI","colab_type":"text"},"source":["# 1. Load data\n","\n","---\n","\\\n","     \n","* data_train.csv, data_test.csv 파일을 동일 디렉터리에 위치시키고 데이터를 읽었습니다.     \n","읽는 과정에서 theta0의 계수를 위해 1을 추가하면서 읽었습니다.       \n"," \n","* 읽은 데이터들을 (x, y, z)와 (h)로 split하여 matrix를 만들었습니다. "]},{"cell_type":"code","metadata":{"id":"eRCVLu34yG-P","colab_type":"code","colab":{}},"source":["import csv\n","import numpy as np\n","import matplotlib.pyplot as plt\n","'''\n","1. Data\n"," - Config\n"," - Load Data\n"," - Split loaded data\n","'''\n","\n","# Config\n","learning_rate=0.00002\n","opt_threshold=1e-5\n","t0, t1, t2, t3=-1., 1., 3., 5.\n","theta=np.array([[t0, t1, t2, t3]])\n","\n","# Load data\n","path = \"drive/My Drive/Classroom/Machine Learning (2) 2020-1\\\n","/class-MachineLearning/assignment04/\"\n","train=[]\n","test=[]\n","\n","with open(path+'data_train.csv', newline='') as myfile:\n","    reader  = csv.reader(myfile, delimiter=',')\n","    ct = 1 \n","    for i in reader:\n","        temp=[1.0, float(i[0]), float(i[1]), float(i[2]), float(i[3])]\n","        train.append(temp)\n","        ct += 1\n","    train_m=ct\n","\n","with open(path+'data_test.csv', newline='') as myfile:\n","    reader  = csv.reader(myfile, delimiter=',')\n","    ct = 1 \n","    for i in reader:\n","        temp=[1.0, float(i[0]), float(i[1]), float(i[2]), float(i[3])]\n","        test.append(temp)\n","        ct += 1\n","    test_m=ct\n","\n","# Split loaded data\n","train=np.array(train)\n","test=np.array(test)\n","train_x, train_y=train[:, :4], train[:, 4]\n","train_y=train_y[:,np.newaxis]\n","test_x, test_y=test[:,:4], test[:,4]\n","test_y=test_y[:,np.newaxis]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E2Z-Q-nWeMph","colab_type":"text"},"source":["# 2. Optimize linear function\n","\n","---\n","\\\n","     \n","* 각각 train, test data에 대한 hypothesis, objective function, gradient descent를 정의했습니다.     \n"," \n","* 연산과정들을 matrix로 빠르게 계산하기 위해 np.dot함수를 사용했습니다.     \n","\n","* 각 theta(feature)들에 맞는 update함수를 정의함으로써 학습동안 각각의 theta들이 모두 update되도록 했습니다.    \n","\n","* 수렴하는 기준을 1e-5로 설정하고 iteration에 대한 loss변화량이 이 기준값보다 작으면 수렴했다 판단했습니다.     "]},{"cell_type":"code","metadata":{"id":"Nybhois3yMVT","colab_type":"code","colab":{}},"source":["'''\n","2. Hypothesis\n"," - Define hypothesis for each train and test\n","\n","3. Objective function\n"," - Define objective function for each train and test\n","\n","4. Gradient Descent\n"," - Define derivations\n"," - Update theta0, theta1, theta2, theta3\n","'''\n","\n","# Define hypothesis\n","def train_hypothesis() : \n","    return train_x.dot(theta.T)\n","\n","def test_hypothesis() : \n","    return test_x.dot(theta.T)\n","\n","train_h=train_hypothesis()\n","test_h=test_hypothesis()\n","\n","# Define objective function\n","def train_objective_function() :\n","    train_J = np.sum((train_h-train_y)**2) / (2*train_m)\n","    return train_J\n","\n","def test_objective_function() :\n","    test_J = np.sum((test_h-test_y)**2) / (2*test_m)\n","    return test_J\n","\n","# Define derivations\n","def dev() :    \n","    dev0=np.sum(train_h-train_y) / train_m\n","    dev1=np.sum(np.squeeze(train_h-train_y)*(train_x[:, 1])) / train_m\n","    dev2=np.sum(np.squeeze(train_h-train_y)*(train_x[:,2])) / train_m\n","    dev3=np.sum(np.squeeze(train_h-train_y)*(train_x[:,3])) / train_m\n","    \n","    dev=[dev0, dev1, dev2, dev3]\n","    return dev\n","\n","# Update theta0, theta1, theta2, theta3\n","def gradient_descent() :\n","    return (theta[0][0]-(learning_rate*dev0), theta[0][1]-(learning_rate*dev1),\\\n","            theta[0][2]-(learning_rate*dev2), theta[0][3]-(learning_rate*dev3))\n","    \n","train_J_list=[]\n","test_J_list=[]\n","theta0_list=[]\n","theta1_list=[]\n","theta2_list=[]\n","theta3_list=[]\n","\n","# Train\n","count=0\n","while(1) :\n","    count+=1\n","    train_J=train_objective_function()\n","    test_J=test_objective_function()\n","\n","    train_J_list.append(train_J)\n","    test_J_list.append(test_J)\n","    theta0_list.append(theta[0][0])\n","    theta1_list.append(theta[0][1])\n","    theta2_list.append(theta[0][2])\n","    theta3_list.append(theta[0][3])\n","\n","    dev0, dev1, dev2, dev3 = dev()\n","    temp0, temp1, temp2, temp3 = theta[0]\n","    theta[0][0], theta[0][1], theta[0][2], theta[0][3] = gradient_descent()\n","    \n","    train_h=train_hypothesis()\n","    test_h=test_hypothesis()\n","    \n","    if len(train_J_list)>=2 and \\\n","    abs(train_J_list[-2] - train_J_list[-1]) <opt_threshold :\n","        break\n","\n","print(\"theta0 : \", theta[0][0])\n","print(\"theta1 : \", theta[0][1])\n","print(\"theta2 : \", theta[0][2])\n","print(\"theta3 : \", theta[0][3])\n","print(\"loss : \", train_J)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3hMR5A-Sgo99","colab_type":"text"},"source":["# 3. Model parameters\n","\n","---\n","\\\n"," - update를 할때마다 변하는 theta0, theta1, theta2, theta3의 값들을 따로 리스트에 저장해뒀었습니다.\n"," \n","*   각 iteration마다 위 theta들이 각각 어떻게 변하는지 시각화했습니다.\n"]},{"cell_type":"code","metadata":{"id":"YxE3HntmgVkz","colab_type":"code","colab":{}},"source":["'''\n","Visualize \n","'''\n","plt.figure(figsize=(10, 7))\n","plt.plot(theta0_list, color='black', label='theta0')\n","plt.plot(theta1_list, color='red', label='theta1')\n","plt.plot(theta2_list, color='green', label='theta2')\n","plt.plot(theta3_list, color='blue', label='theta3')\n","plt.legend(loc='upper right')\n","plt.xlabel(\"iteration\")\n","plt.xlim(left=-1000)\n","plt.ylabel(\"value\")\n","plt.title(\"Parameter (theta0 & theta1\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8APDEcMfitys","colab_type":"text"},"source":["# 4. Energy Values (training data)\n","\n","---\n","\\\n"," - training data에 대해서 update를 할때마다 J_list에 그동안의 J(objective function의 value) 값들을 넣었습니다.  \n"," \n","*   각 iteration마다 J값이 어떻게 변하는지 시각화했습니다.\n"]},{"cell_type":"code","metadata":{"id":"TrlJEhoKoA2v","colab_type":"code","colab":{}},"source":["'''\n","Visualize training error at every iteration\n","'''\n","plt.figure(figsize=(10, 7))\n","plt.plot(train_J_list, color='blue', label='train')\n","plt.xlabel(\"iteration\")\n","plt.ylim(top=1000, bottom=0)\n","plt.xlim(right=10000, left=-1000)\n","plt.ylabel(\"cost\")\n","plt.legend(loc='upper right')\n","plt.title(\"Energy values (train)\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ry0fNqQUjGij","colab_type":"text"},"source":["# 5. Energy Values (test data)\n","\n","---\n","\\\n"," - training data를 이용해 update를 할때마다 test_J_list에 test data에 대한 loss 값들을 넣었습니다.  \n"," \n","*   각 iteration마다 J값이 어떻게 변하는지 시각화했습니다.\n"]},{"cell_type":"code","metadata":{"id":"oiVb05swyOkm","colab_type":"code","colab":{}},"source":["'''\n","Visualize training error at every iteration\n","'''\n","plt.figure(figsize=(10, 7))\n","plt.plot(test_J_list, color='red', label='test')\n","plt.xlabel(\"iteration\")\n","plt.ylim(top=1000, bottom=-20)\n","plt.xlim(right=10000, left=-1000)\n","plt.ylabel(\"cost\")\n","plt.legend(loc='upper right')\n","plt.title(\"Energy values (test)\")\n","plt.show()"],"execution_count":0,"outputs":[]}]}