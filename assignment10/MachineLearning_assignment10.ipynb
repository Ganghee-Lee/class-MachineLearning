{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MachineLearning_assignment10.ipynb","provenance":[{"file_id":"1hd9YVjY_RkljM1jXFo8ZaG25JxJ0pzyZ","timestamp":1590816167731}],"private_outputs":true,"mount_file_id":"129zK17IXWh6mYlbr2Uim1WF3C483U3wr","authorship_tag":"ABX9TyMW+ALCDB8qsO0FBG8YR7y3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"moZ1vjCDxiNm","colab_type":"code","colab":{}},"source":["!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n","!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n","!pip install cupy-cuda80"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFHVtxzsmEjv","colab_type":"code","colab":{}},"source":["'''\n","# Dropout\n"," - 1. Training FW propagation 에서 dropout 적용\n"," - 2. Predict에서는 keep_prob 만큼 다시 곱해줌 (70퍼센트 노드사용하도록 학습했었으므로)\n"," - 3. Training BW propagation 에서 dropout 적용\n","\n","Layer 구조\n","Input layer : 784\n","hidden layer 3개 : 512, 512, 512\n","Output layer : 10\n","'''\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cupy as cp\n","from termcolor import colored\n","file_data   = \"drive/My Drive/Classroom/Machine Learning (2) 2020-1\\\n","/class-MachineLearning/assignment10/mnist.csv\"\n","handle_file = open(file_data, \"r\")\n","data        = handle_file.readlines()\n","handle_file.close()\n","\n","size_row    = 28    # height of the image\n","size_col    = 28    # width of the image\n","\n","num_image   = len(data)\n","count       = 0     # count for the number of images\n","\n","#\n","# normalize the values of the input data to be [0, 1]\n","#\n","def normalize(data):\n","\n","    data_normalized = (data - min(data)) / (max(data) - min(data))\n","\n","    return(data_normalized)\n","\n","#\n","# example of distance function between two vectors x and y\n","#\n","def distance(x, y):\n","\n","    d = (x - y) ** 2\n","    s = np.sum(d)\n","    # r = cp.sqrt(s)\n","\n","    return(s)\n","\n","#\n","# make a matrix each column of which represents an images in a vector form\n","#\n","list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n","list_label  = np.empty(num_image, dtype=int)\n","idx_label = [[] for i in range(10)]\n","for line in data:\n","\n","    line_data   = line.split(',')\n","    label       = line_data[0]\n","    im_vector   = np.asfarray(line_data[1:])\n","    im_vector   = normalize(im_vector)\n","    list_label[count]       = label\n","    list_image[:, count]    = im_vector\n","    idx_label[int(label)].append(count)\n","    count += 1\n","\n","#\n","# plot the average image of all the images for each digit\n","#\n","f2 = plt.figure(2)\n","\n","im_average  = np.zeros((size_row * size_col, 10), dtype=float)\n","im_count    = np.zeros(10, dtype=int)\n","\n","for i in range(num_image):\n","\n","    im_average[:, list_label[i]] += list_image[:, i]\n","    im_count[list_label[i]] += 1\n","\n","for i in range(10):\n","\n","    im_average[:, i] /= im_count[i]\n","\n","    plt.subplot(2, 5, i+1)\n","    plt.title(i)\n","    plt.imshow(im_average[:,i].reshape((size_row, size_col)), cmap='Greys', interpolation='None')\n","\n","    frame   = plt.gca()\n","    frame.axes.get_xaxis().set_visible(False)\n","    frame.axes.get_yaxis().set_visible(False)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3X2VH2oRJSV","colab_type":"code","colab":{}},"source":["'''\n","Config\n","'''\n","\n","learning_rate = 1e-3\n","batch_size=100\n","#input_data=cp.vstack((bias, list_image))\n","list_image = cp.array(list(list_image))\n","one_hot=cp.zeros((10, num_image))\n","for i in range(num_image) :\n","    one_hot[list_label[i]][i]=1\n","\n","train_image = list_image[:, :1000]\n","train_label = one_hot[:, :1000]\n","\n","# batch_image = list_image[:, :100]\n","# batch_label = train_label[:, :100]\n","\n","test_image = list_image[:, 1000:]\n","test_label = one_hot[:, 1000:]\n","\n","num_train = train_image.shape[1]\n","num_test = test_image.shape[1]\n","\n","#input_data= cp.vstack(((cp.full((1, list_image.shape[1]), bias0)), list_image))\n","\n","# layer1=np.empty((196, num_train), dtype=float)\n","# layer2=np.empty((49, num_train), dtype=float)\n","# layer3=np.empty((10, num_train), dtype=float)\n","# layers=[train_image, layer1, layer2, layer3]\n","\n","layer1=cp.empty((512, num_train), dtype=float)\n","layer2=cp.empty((512, num_train), dtype=float)\n","layer3=cp.empty((512, num_train), dtype=float)\n","layer4=cp.empty((10, num_train), dtype=float)\n","layers=[train_image, layer1, layer2, layer3, layer4]\n","\n","# std_w0 = np.sqrt(2/980)\n","# weight0=np.random.normal(0., std_w0, (196, size_row * size_col))\n","# std_w1 = np.sqrt(2/245)\n","# weight1=np.random.normal(0., std_w1, (49, 196))\n","# std_w2 = np.sqrt(2/59)\n","# weight2=np.random.normal(0., std_w2, (10, 49))\n","# weights=[weight0, weight1, weight2]\n","\n","std_w0 = cp.sqrt(2/1296)\n","weight0=cp.random.normal(0., std_w0, (512, size_row * size_col))\n","std_w1 = cp.sqrt(2/1024)\n","weight1=cp.random.normal(0., std_w1, (512, 512))\n","std_w2 = cp.sqrt(2/1024)\n","weight2=cp.random.normal(0., std_w2, (512, 512))\n","std_w3 = cp.sqrt(2/522)\n","weight3=cp.random.normal(0., std_w2, (10, 512))\n","weights=[weight0, weight1, weight2, weight3]\n","\n","# m_t=[np.zeros((196, 784)), np.zeros((49, 196)), np.zeros((10, 49))]\n","# v_t=[np.zeros((196, 784)), np.zeros((49, 196)), np.zeros((10, 49))]\n","\n","m_t=[cp.zeros((512, 784)), cp.zeros((512, 512)), cp.zeros((512, 512)), cp.zeros((10, 512))]\n","v_t=[cp.zeros((512, 784)), cp.zeros((512, 512)), cp.zeros((512, 512)), cp.zeros((10, 512))]\n","\n","# bias0, bias1, bias2 = 0.1, 0.1, 0.1\n","# biases=[bias0, bias1, bias2]\n","\n","bias0, bias1, bias2, bias3 = 0.1, 0.1, 0.1, 0.1\n","biases=[bias0, bias1, bias2, bias3]\n","\n","train_loss=[]\n","train_accuracy=[]\n","\n","test_loss=[]\n","test_accuracy=[]\n","\n","print(num_train)\n","print(num_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VA8imousOhvP","colab_type":"code","colab":{}},"source":["#a0=np.zeros(())\n","# do=[0, 0, 1]\n","do=[0, 0, 0, 1]\n","def sigmoid(x) :\n","    return 1/(1+cp.exp(-x))\n","'''\n","def batch() :\n","    batch_mask = np.random.choice(num_train, batch_size)\n","    layers[0] = train_image[:, batch_mask]\n","    batch_label = train_label[:, batch_mask]\n","'''\n","def fw_propagation() :\n","    #a_list=[]\n","    #input_data = np.vstack(((np.full((1, list_image.shape[1]), bias0)), list_image))\n","    for i in range(len(weights)-1) :\n","        do[i] = cp.random.binomial(1, 0.7, size=layers[i+1].shape)\n","\n","    # do[0]=np.random.binomial(1, 0.7, size=layers[1].shape)\n","    # do[1]=np.random.binomial(1, 0.7, size=layers[2].shape)\n","    # do[2]=np.random.binomial(1, 0.7, size=layers[3].shape)\n","    for i in range(len(weights)) :\n","        layers[i+1]=sigmoid(weights[i] @ layers[i]) * do[i]\n","\n","def predict() :\n","    for i in range(len(weights)) :\n","        if i==0 : \n","            output = sigmoid(weights[i] @ test_image) * 0.7\n","        elif i==len(weights)-1 : \n","            output = sigmoid(weights[i] @ output)\n","        else :\n","            output = sigmoid(weights[i] @ output) * 0.7\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQvwn4MuLtRq","colab_type":"code","colab":{}},"source":["\n","'''\n","Back propagation\n","'''\n","\n","beta1, beta2 = 0.9, 0.999\n","eps=1e-8\n","t=0\n","def bw_propagation() :\n","    global t, m_t, v_t, eps, beta1, beta2\n","    dev_h=layers[-1] - train_label\n","    t+=1\n","    for i in range(len(weights)-1, -1, -1) :\n","        dev_w=dev_h @ layers[i].T\n","        if i==0 : \n","            pass\n","        else :\n","            dev_h=weights[i].T @ dev_h * layers[i] * (1-layers[i]) * do[i-1]\n","        \n","        m_t[i] = beta1*m_t[i] + (1-beta1)*dev_w / num_train\n","        v_t[i] = beta2*v_t[i] + (1-beta2)*cp.power((dev_w/num_train), 2)\n","        m_hat=m_t[i]/(1-(beta1**t))\n","        v_hat=v_t[i]/(1-(beta2**t))\n","        weights[i] -= (learning_rate*m_hat)/(cp.sqrt(v_hat) + eps)\n","        #weights[i] -= learning_rate * dev_w / num_train\n","\n","        \n","\n","\n","def loss(output, label) :\n","    return cp.mean(cp.sum(-label*cp.log(output) - (1-label)*cp.log(1-output), axis=0))\n","def accuracy(output, label):\n","  return (output == label.argmax(axis = 0)).mean()*100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdXTuwDl0t5I","colab_type":"code","colab":{}},"source":["import time\n","start = time.time() \n","for i in range(50000) :\n","    # input_data, a0, a1, a2 = fw_propagation()\n","    if i%500==0 :\n","        print(\"time :\", time.time() - start)\n","    fw_propagation()\n","    bw_propagation()\n","    p = predict()\n","    train_loss.append(loss(layers[-1], train_label))\n","    test_loss.append(loss(p, test_label))\n","    train_accuracy.append(accuracy(layers[-1].argmax(axis=0), train_label))\n","    test_accuracy.append(accuracy(p.argmax(axis=0), test_label))\n","print(\"time :\", time.time() - start)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuTQf9w52sJ7","colab_type":"code","colab":{}},"source":["'''\n","Visualize Loss\n","'''\n","plt.figure(figsize=(8, 5))\n","plt.plot(train_loss, color='blue', label='train')\n","plt.plot(test_loss, color='red', label='test')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"cost\")\n","plt.legend(loc='upper right')\n","plt.title(\"Loss\")\n","plt.show()\n","print(test_loss[-10:])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uah51A63CZ6","colab_type":"code","colab":{}},"source":["print(test_accuracy[-10 :])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoK8V5GU2taD","colab_type":"code","colab":{}},"source":["'''\n","Visualize accuracy\n","'''\n","print(test_accuracy.index(np.max(test_accuracy)))\n","print(np.max(test_accuracy))\n","plt.figure(figsize=(8, 5))\n","plt.plot(train_accuracy, color='blue', label='train')\n","plt.plot(test_accuracy, color='red', label='test')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"accuracy\")\n","plt.legend(loc='upper right')\n","plt.title(\"Accuracy\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BOItt3v6HNt","colab_type":"text"},"source":["# 1. Plot the loss curve\n","\n","---\n","\\\n","     \n","* train loss는 파란색, test loss는 빨간색으로 plot했습니다."]},{"cell_type":"code","metadata":{"id":"gqgTbLGc5ADM","colab_type":"code","colab":{}},"source":["'''\n","Visualize Loss\n","'''\n","plt.figure(figsize=(8, 5))\n","plt.plot(train_loss, color='blue', label='train')\n","plt.plot(test_loss, color='red', label='test')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"cost\")\n","plt.legend(loc='upper right')\n","plt.title(\"Loss\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bgn1T_c56WG0","colab_type":"text"},"source":["# 2. Plot the accuracy curve\n","\n","---\n","\\\n","     \n","* train accuracy는 파란색, test accuracy는 빨간색으로 plot했습니다."]},{"cell_type":"code","metadata":{"id":"Bl9XCscGJt23","colab_type":"code","colab":{}},"source":["'''\n","Visualize accuracy\n","'''\n","plt.figure(figsize=(8, 5))\n","plt.plot(train_accuracy, color='blue', label='train')\n","plt.plot(test_accuracy, color='red', label='test')\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"accuracy\")\n","plt.legend(loc='upper right')\n","plt.title(\"Accuracy\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZCF6Onrm6oBg","colab_type":"text"},"source":["# 3. Plot the accuracy value\n","\n","---\n","\\\n","     \n","* train accuracy는 파란색, test accuracy는 빨간색으로 print했습니다."]},{"cell_type":"code","metadata":{"id":"LgQ4EUjgdDaJ","colab_type":"code","colab":{}},"source":["print(\"<Final accuracy>\")\n","print('-'*50)\n","train_final='train accuracy : '+str(train_accuracy[-1]) + '%'\n","test_final='test accuracy : '+str(test_accuracy[-1]) + '%'\n","print(colored(train_final, 'blue'))\n","print(colored(test_final, 'red'))\n","print('-'*50)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-IKtQ_A36vuP","colab_type":"text"},"source":["# 4. Plot the classification example\n","\n","---\n","\\\n","     \n","* 첫번째는 test image에서 답을 맞춘 경우, 두번째는 틀린 경우를 plot했습니다."]},{"cell_type":"code","metadata":{"id":"sRYC8owy7ibK","colab_type":"code","colab":{}},"source":["#plt.figure(figsize=(15,3))\n","pred = p.argmax(axis=0)\n","label = test_label.argmax(axis=0)\n","\n","count=1\n","print(\"<Correct>\")\n","print(\"-\"*35)\n","for i in range(len(label)) :\n","    if pred[i] == label[i] :\n","        plt.subplot(2, 5, count)\n","        plt.title(pred[i])\n","        plt.imshow(test_image[:, i].reshape(28, 28), cmap='Greys', interpolation='None')\n","        frame = plt.gca()\n","        frame.axes.get_xaxis().set_visible(False)\n","        frame.axes.get_yaxis().set_visible(False)\n","        count+=1\n","    if count >10 :\n","        break\n","plt.show()\n","\n","count=1\n","print(\"<Wrong>\")\n","print(\"-\"*35)\n","for i in range(len(label)) :\n","    if pred[i] != label[i] :\n","        plt.subplot(2, 5, count)\n","        plt.title(pred[i])\n","        plt.imshow(test_image[:, i].reshape(28, 28), cmap='Greys', interpolation='None')\n","        frame = plt.gca()\n","        frame.axes.get_xaxis().set_visible(False)\n","        frame.axes.get_yaxis().set_visible(False)\n","        count+=1\n","    if count >10 :\n","        break\n","plt.show()"],"execution_count":0,"outputs":[]}]}